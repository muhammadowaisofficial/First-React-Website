"use strict";
var __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
var _LocalFileSourceProvider_instances, _LocalFileSourceProvider_getBackupStream, _LocalFileSourceProvider_streamJsonlDirectory, _LocalFileSourceProvider_parseJSONFile;
Object.defineProperty(exports, "__esModule", { value: true });
exports.createLocalFileSourceProvider = void 0;
const fs_1 = __importDefault(require("fs"));
const zlib_1 = __importDefault(require("zlib"));
const tar_1 = __importDefault(require("tar"));
const fp_1 = require("lodash/fp");
const stream_chain_1 = require("stream-chain");
const stream_1 = require("stream");
const Parser_1 = require("stream-json/jsonl/Parser");
const encryption_1 = require("../encryption");
const utils_1 = require("../utils");
/**
 * Constant for the metadata file path
 */
const METADATA_FILE_PATH = 'metadata.json';
const createLocalFileSourceProvider = (options) => {
    return new LocalFileSourceProvider(options);
};
exports.createLocalFileSourceProvider = createLocalFileSourceProvider;
class LocalFileSourceProvider {
    constructor(options) {
        _LocalFileSourceProvider_instances.add(this);
        this.type = 'source';
        this.name = 'source::local-file';
        this.options = options;
        if (this.options.encrypted && this.options.encryptionKey === undefined) {
            throw new Error('Missing encryption key');
        }
    }
    /**
     * Pre flight checks regarding the provided options (making sure that the provided path is correct, etc...)
     */
    bootstrap() {
        const path = this.options.backupFilePath;
        const isValidBackupPath = fs_1.default.existsSync(path);
        // Check if the provided path exists
        if (!isValidBackupPath) {
            throw new Error(`Invalid backup file path provided. "${path}" does not exist on the filesystem.`);
        }
    }
    getMetadata() {
        // TODO: need to read the file & extract the metadata json file
        // => we might also need to read the schema.jsonl files & implements a custom stream-check
        const backupStream = __classPrivateFieldGet(this, _LocalFileSourceProvider_instances, "m", _LocalFileSourceProvider_getBackupStream).call(this);
        return __classPrivateFieldGet(this, _LocalFileSourceProvider_instances, "m", _LocalFileSourceProvider_parseJSONFile).call(this, backupStream, METADATA_FILE_PATH);
    }
    async getSchemas() {
        const schemas = await (0, utils_1.collect)(this.streamSchemas());
        return (0, fp_1.keyBy)('uid', schemas);
    }
    streamEntities() {
        return __classPrivateFieldGet(this, _LocalFileSourceProvider_instances, "m", _LocalFileSourceProvider_streamJsonlDirectory).call(this, 'entities');
    }
    streamSchemas() {
        return __classPrivateFieldGet(this, _LocalFileSourceProvider_instances, "m", _LocalFileSourceProvider_streamJsonlDirectory).call(this, 'schemas');
    }
    streamLinks() {
        return __classPrivateFieldGet(this, _LocalFileSourceProvider_instances, "m", _LocalFileSourceProvider_streamJsonlDirectory).call(this, 'links');
    }
    streamConfiguration() {
        // NOTE: TBD
        return __classPrivateFieldGet(this, _LocalFileSourceProvider_instances, "m", _LocalFileSourceProvider_streamJsonlDirectory).call(this, 'configuration');
    }
}
_LocalFileSourceProvider_instances = new WeakSet(), _LocalFileSourceProvider_getBackupStream = function _LocalFileSourceProvider_getBackupStream(decompress = true) {
    const path = this.options.backupFilePath;
    const readStream = fs_1.default.createReadStream(path);
    const streams = [readStream];
    // Handle decompression
    if (decompress) {
        streams.push(zlib_1.default.createGunzip());
    }
    return (0, stream_chain_1.chain)(streams);
}, _LocalFileSourceProvider_streamJsonlDirectory = function _LocalFileSourceProvider_streamJsonlDirectory(directory) {
    const options = this.options;
    const inStream = __classPrivateFieldGet(this, _LocalFileSourceProvider_instances, "m", _LocalFileSourceProvider_getBackupStream).call(this);
    const outStream = new stream_1.PassThrough({ objectMode: true });
    (0, stream_1.pipeline)([
        inStream,
        new tar_1.default.Parse({
            filter(path, entry) {
                if (entry.type !== 'File') {
                    return false;
                }
                const parts = path.split('/');
                if (parts.length !== 2) {
                    return false;
                }
                return parts[0] === directory;
            },
            onentry(entry) {
                const transforms = [];
                if (options.encrypted) {
                    transforms.push((0, encryption_1.createDecryptionCipher)(options.encryptionKey));
                }
                if (options.compressed) {
                    transforms.push(zlib_1.default.createGunzip());
                }
                transforms.push(
                // JSONL parser to read the data chunks one by one (line by line)
                (0, Parser_1.parser)(), 
                // The JSONL parser returns each line as key/value
                (line) => line.value);
                entry
                    // Pipe transforms
                    .pipe((0, stream_chain_1.chain)(transforms))
                    // Pipe the out stream to the whole pipeline
                    // DO NOT send the 'end' event when this entry has finished
                    // emitting data, so that it doesn't close the out stream
                    .pipe(outStream, { end: false });
            },
        }),
    ], () => {
        // Manually send the 'end' event to the out stream
        // once every entry has finished streaming its content
        outStream.end();
    });
    return outStream;
}, _LocalFileSourceProvider_parseJSONFile = async function _LocalFileSourceProvider_parseJSONFile(fileStream, filePath) {
    return new Promise((resolve, reject) => {
        (0, stream_1.pipeline)([
            fileStream,
            // Custom backup archive parsing
            new tar_1.default.Parse({
                /**
                 * Filter the parsed entries to only keep the one that matches the given filepath
                 */
                filter(path, entry) {
                    return path === filePath && entry.type === 'File';
                },
                /**
                 * Whenever an entry passes the filter method, process it
                 */
                async onentry(entry) {
                    // Collect all the content of the entry file
                    const content = await entry.collect();
                    // Parse from buffer to string to JSON
                    const parsedContent = JSON.parse(content.toString());
                    // Resolve the Promise with the parsed content
                    resolve(parsedContent);
                    // Cleanup (close the stream associated to the entry)
                    entry.destroy();
                },
            }),
        ], () => {
            // If the promise hasn't been resolved and we've parsed all
            // the archive entries, then the file doesn't exist
            reject(`${filePath} not found in the archive stream`);
        });
    });
};
//# sourceMappingURL=local-file-source-provider.js.map